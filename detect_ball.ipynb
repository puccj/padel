{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a video file and display it frame by frame\n",
    "\n",
    "import cv2\n",
    "path = \"input_videos/27-11-2024-21-02.mp4\"\n",
    "cap = cv2.VideoCapture(path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add detected people to the video frames using YOLOv8\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "cap = cv2.VideoCapture(path)\n",
    "\n",
    "# Check if the video was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"End of video or failed to read frame.\")\n",
    "        break\n",
    "\n",
    "    # Run YOLOv8 inference on the frame\n",
    "    results = model(frame)[0]\n",
    "    id_name_dict = results.names\n",
    "\n",
    "    for box in results.boxes:\n",
    "        object_cls_id = box.cls.tolist()[0]\n",
    "        if id_name_dict[object_cls_id] == \"person\":\n",
    "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
    "\n",
    "    # Visualize the results on the frame\n",
    "    # annotated_frame = results.plot()  # Draw bounding boxes and labels\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow(\"YOLOv8 Inference\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the ball using frame differencing\n",
    "\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(path)\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "thresh = 30\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_diff = cv2.absdiff(old_gray, frame_gray)\n",
    "\n",
    "    _, thresholded = cv2.threshold(frame_diff, thresh, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"original\", frame)\n",
    "    cv2.imshow(\"thresholded\", thresholded)\n",
    "\n",
    "    if cv2.waitKey(0) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    old_gray = frame_gray\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove people to detect only the ball\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from itertools import chain\n",
    "\n",
    "path = \"input_videos/27-11-2024-21-02-second.mp4\"\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "cap = cv2.VideoCapture(path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "success, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "thresh = 30\n",
    "min_area = 100\n",
    "\n",
    "results = model(old_frame)[0]\n",
    "id_name_dict = results.names\n",
    "old_boxes = results.boxes\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_diff = cv2.absdiff(old_gray, frame_gray)\n",
    "\n",
    "    _, thresholded = cv2.threshold(frame_diff, thresh, 255, cv2.THRESH_BINARY)\n",
    "    results = model(frame)[0]\n",
    "    id_name_dict = results.names\n",
    "\n",
    "    for box in chain(old_boxes, results.boxes):\n",
    "        object_cls_id = box.cls.tolist()[0]\n",
    "        if id_name_dict[object_cls_id] == \"person\":\n",
    "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), 0, -1)\n",
    "            thresholded[int(y1):int(y2), int(x1):int(x2)] = 0\n",
    "\n",
    "    # thresholded = cv2.erode(thresholded, None, iterations=4)\n",
    "    # thresholded = cv2.dilate(thresholded, None, iterations=4)\n",
    "\n",
    "    # draw the ball\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > min_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"original\", frame)\n",
    "    cv2.imshow(\"thresholded\", thresholded)\n",
    "\n",
    "    if cv2.waitKey(0) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    old_gray = frame_gray\n",
    "    old_boxes = results.boxes\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO segmentation\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "model = YOLO(\"yolov8s-seg.pt\")  # You can use 'yolov8n-seg.pt' for a smaller model\n",
    "path = \"input_videos/27-11-2024-21-02-second.mp4\"\n",
    "cap = cv2.VideoCapture(path)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "# fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Output video writer\n",
    "# out = cv2.VideoWriter(\"output.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)\n",
    "\n",
    "    for result in results:\n",
    "        masks = result.masks  # Get segmentation masks\n",
    "        \n",
    "        if masks is None:\n",
    "            continue\n",
    "\n",
    "        for mask, cls in zip(masks.data, result.boxes.cls):\n",
    "            if int(cls) == 0:  # Class 0 corresponds to 'person'\n",
    "                mask = mask.cpu().numpy()  # Convert mask to NumPy\n",
    "                mask = cv2.resize(mask, (frame_width, frame_height))  # Resize mask to match frame\n",
    "                mask = (mask > 0.5).astype(np.uint8) * 255  # Convert to binary mask\n",
    "\n",
    "                # Create a color overlay for the mask\n",
    "                color_mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "                color_mask[:, :, 0] = mask  # Blue channel (you can change color)\n",
    "\n",
    "                # Blend mask with the frame\n",
    "                frame = cv2.addWeighted(frame, 1, color_mask, 0.5, 0)\n",
    "\n",
    "    # Write frame to output\n",
    "    # out.write(frame)\n",
    "\n",
    "    # Show frame (press 'q' to exit)\n",
    "    cv2.imshow(\"YOLO Segmentation\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "# out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use YOLO segmentation model to remove people from the video frames and detect ball\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from itertools import chain\n",
    "\n",
    "# Load YOLOv8 Segmentation model\n",
    "path = \"input_videos/27-11-2024-21-02-second.mp4\"\n",
    "model = YOLO(\"yolov8n-seg.pt\")  # Segmentation model instead of detection\n",
    "cap = cv2.VideoCapture(path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Read the first frame and convert to grayscale\n",
    "success, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Motion detection parameters\n",
    "thresh = 30\n",
    "min_area = 3\n",
    "\n",
    "# Detect people on previous frame\n",
    "old_results = model(old_frame)[0]\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_diff = cv2.absdiff(old_gray, frame_gray)\n",
    "\n",
    "    # Threshold the difference image\n",
    "    _, thresholded = cv2.threshold(frame_diff, thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Run YOLO segmentation\n",
    "    results = model(frame)[0]  # Run inference\n",
    "\n",
    "    if results.masks is None and old_results.masks is None:\n",
    "        continue\n",
    "\n",
    "    for mask, cls in zip(chain(results.masks.data, old_results.masks.data),\n",
    "                         chain(results.boxes.cls,  old_results.boxes.cls )):\n",
    "\n",
    "        if int(cls) != 0 and int(cls) != 38:  # 0 = 'person'  38 = 'tennis racket'\n",
    "            continue\n",
    "\n",
    "        mask = mask.cpu().numpy()  # Convert to NumPy array\n",
    "        mask = cv2.resize(mask, (frame.shape[1], frame.shape[0]))  # Resize to frame size\n",
    "        mask = (mask > 0.5).astype(np.uint8) * 255  # Convert to binary mask\n",
    "        \n",
    "        # Expand the mask to cover more of the border\n",
    "        kernel = np.ones((20, 20), np.uint8)  # Adjust the size (larger = more expansion)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)  # Expand the mask\n",
    "\n",
    "        # Remove people from the original frame and thresholded image\n",
    "        frame[mask > 0] = 0  # Set pixels to black\n",
    "        thresholded[mask > 0] = 0  # Remove motion detection in people regions\n",
    "\n",
    "    # Find contours and draw bounding boxes around them\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > min_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw ball bounding box\n",
    "\n",
    "    # Show frames\n",
    "    cv2.imshow(\"Original\", frame)\n",
    "    cv2.imshow(\"Thresholded\", thresholded)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(0) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    # Update previous frame\n",
    "    old_gray = frame_gray\n",
    "    old_results = results\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video or failed to read frame.\n"
     ]
    }
   ],
   "source": [
    "# Check if the two videos are synchronized.\n",
    "# Consider that one video is 20fps, the other is 10fps\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the two videos\n",
    "path1 = \"input_videos/27-11-2024-21-02.mp4\"\n",
    "path2 = \"input_videos/27-11-2024-21-02-second.mp4\"\n",
    "cap1 = cv2.VideoCapture(path1)\n",
    "cap2 = cv2.VideoCapture(path2)\n",
    "\n",
    "# Check if the videos were opened successfully\n",
    "if not cap1.isOpened() or not cap2.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap1.isOpened() and cap2.isOpened():\n",
    "    # Read a frame from each video\n",
    "    ret1, a = cap1.read()   # discard frame since 20fps vs 10fps\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    # Check if frames were read successfully\n",
    "    if not ret1 or not ret2:\n",
    "        print(\"End of video or failed to read frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frames side by side\n",
    "    frame = np.hstack((frame1, frame2))\n",
    "    cv2.imshow(\"Synchronized Videos\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(0) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video capture objects and close the display window\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "# THEY ARE NOT SYNCHRONIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually synchronize the two videos\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "path1 = \"input_videos/27-11-2024-21-02.mp4\"\n",
    "path2 = \"input_videos/27-11-2024-21-02-second.mp4\"\n",
    "cap1 = cv2.VideoCapture(path1)\n",
    "cap2 = cv2.VideoCapture(path2)\n",
    "\n",
    "if not cap1.isOpened() or not cap2.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Skip the first n frames of the first video to synchronize\n",
    "for _ in range(3):\n",
    "    ret1, frame1 = cap1.read()\n",
    "\n",
    "while cap1.isOpened() and cap2.isOpened():\n",
    "    ret1, frame1 = cap1.read()  # discard frame since 20fps vs 10fps\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    if not ret1 or not ret2:\n",
    "        print(\"End of video or failed to read frame.\")\n",
    "        break\n",
    "\n",
    "    frame = np.hstack((frame1, frame2))\n",
    "    cv2.imshow(\"Synchronized Videos\", frame)\n",
    "\n",
    "    if cv2.waitKey(0) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save possible positions to a file (from first video)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from itertools import chain\n",
    "import csv\n",
    "\n",
    "# Load YOLOv8 Segmentation model\n",
    "path = \"input_videos/27-11-2024-21-02.mp4\"\n",
    "model = YOLO(\"yolov8n-seg.pt\")  # Segmentation model instead of detection\n",
    "cap = cv2.VideoCapture(path)\n",
    "output_file = \"balls1.csv\"\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Read the first frame and convert to grayscale\n",
    "success, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Motion detection parameters\n",
    "thresh = 30\n",
    "min_area = 3\n",
    "\n",
    "# Detect people on previous frame\n",
    "old_results = model(old_frame)[0]\n",
    "\n",
    "frame_num = 0\n",
    "\n",
    "# Create the file (erasing it if it already exists)\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    pass\n",
    "\n",
    "# Skip the first n frames of the first video to synchronize\n",
    "for _ in range(3):\n",
    "    ret1, frame1 = cap1.read()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read() # Discard half of the frames since 20fps vs 10fps\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_diff = cv2.absdiff(old_gray, frame_gray)\n",
    "\n",
    "    # Threshold the difference image\n",
    "    _, thresholded = cv2.threshold(frame_diff, thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Run YOLO segmentation\n",
    "    results = model(frame)[0]  # Run inference\n",
    "\n",
    "    if results.masks is None and old_results.masks is None:\n",
    "        continue\n",
    "\n",
    "\n",
    "    for mask, cls in zip(chain(results.masks.data, old_results.masks.data),\n",
    "                         chain(results.boxes.cls,  old_results.boxes.cls )):\n",
    "\n",
    "        if int(cls) != 0 and int(cls) != 38:  # 0 = 'person'  38 = 'tennis racket'\n",
    "            continue\n",
    "\n",
    "        mask = mask.cpu().numpy()  # Convert to NumPy array\n",
    "        mask = cv2.resize(mask, (frame.shape[1], frame.shape[0]))  # Resize to frame size\n",
    "        mask = (mask > 0.5).astype(np.uint8) * 255  # Convert to binary mask\n",
    "\n",
    "        # Expand the mask to cover more of the border\n",
    "        kernel = np.ones((20, 20), np.uint8)  # Adjust the size (larger = more expansion)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)  # Expand the mask\n",
    "\n",
    "        # Remove people from the original frame and thresholded image\n",
    "        frame[mask > 0] = 0  # Set pixels to black\n",
    "        thresholded[mask > 0] = 0  # Remove motion detection in people regions\n",
    "\n",
    "    balls_positions = []\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > min_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw ball bounding box\n",
    "            balls_positions.append(np.float32([x+w/2, y+h/2]))\n",
    "            \n",
    "    # Show frames\n",
    "    cv2.imshow(\"Original\", frame)\n",
    "    cv2.imshow(\"Thresholded\", thresholded)\n",
    "\n",
    "    # Save the frame number and ball positions to a file\n",
    "    frame_data = {\n",
    "        \"frame_num\": frame_num,\n",
    "        \"balls\": balls_positions\n",
    "    }\n",
    "    with open(output_file, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        row = [frame_data[\"frame_num\"]] + [pos for pos in frame_data[\"balls\"]]\n",
    "        writer.writerow(row)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    # Update previous frame\n",
    "    frame_num += 1\n",
    "    old_gray = frame_gray\n",
    "    old_results = results\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing for the second video\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from itertools import chain\n",
    "import csv\n",
    "\n",
    "# Load YOLOv8 Segmentation model\n",
    "path = \"input_videos/27-11-2024-21-02-second.mp4\"\n",
    "model = YOLO(\"yolov8n-seg.pt\")  # Segmentation model instead of detection\n",
    "cap = cv2.VideoCapture(path)\n",
    "output_file = \"balls2.csv\"\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Read the first frame and convert to grayscale\n",
    "success, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Motion detection parameters\n",
    "thresh = 30\n",
    "min_area = 3\n",
    "\n",
    "# Detect people on previous frame\n",
    "old_results = model(old_frame)[0]\n",
    "\n",
    "frame_num = 0\n",
    "\n",
    "# Create the file (erasing it if it already exists)\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    pass\n",
    "\n",
    "while cap.isOpened():\n",
    "    # ret, frame = cap.read() # Do NOT discard half of the frames\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_diff = cv2.absdiff(old_gray, frame_gray)\n",
    "\n",
    "    # Threshold the difference image\n",
    "    _, thresholded = cv2.threshold(frame_diff, thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Run YOLO segmentation\n",
    "    results = model(frame)[0]  # Run inference\n",
    "\n",
    "    if results.masks is None and old_results.masks is None:\n",
    "        continue\n",
    "\n",
    "\n",
    "    for mask, cls in zip(chain(results.masks.data, old_results.masks.data),\n",
    "                         chain(results.boxes.cls,  old_results.boxes.cls )):\n",
    "\n",
    "        if int(cls) != 0 and int(cls) != 38:  # 0 = 'person'  38 = 'tennis racket'\n",
    "            continue\n",
    "\n",
    "        mask = mask.cpu().numpy()  # Convert to NumPy array\n",
    "        mask = cv2.resize(mask, (frame.shape[1], frame.shape[0]))  # Resize to frame size\n",
    "        mask = (mask > 0.5).astype(np.uint8) * 255  # Convert to binary mask\n",
    "\n",
    "        # Expand the mask to cover more of the border\n",
    "        kernel = np.ones((20, 20), np.uint8)  # Adjust the size (larger = more expansion)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)  # Expand the mask\n",
    "\n",
    "        # Remove people from the original frame and thresholded image\n",
    "        frame[mask > 0] = 0  # Set pixels to black\n",
    "        thresholded[mask > 0] = 0  # Remove motion detection in people regions\n",
    "\n",
    "    balls_positions = []\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > min_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw ball bounding box\n",
    "            balls_positions.append(np.float32([x+w/2, y+h/2]))\n",
    "            \n",
    "    # Show frames\n",
    "    cv2.imshow(\"Original\", frame)\n",
    "    cv2.imshow(\"Thresholded\", thresholded)\n",
    "\n",
    "    # Save the frame number and ball positions to a file\n",
    "    frame_data = {\n",
    "        \"frame_num\": frame_num,\n",
    "        \"balls\": balls_positions\n",
    "    }\n",
    "    with open(output_file, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        row = [frame_data[\"frame_num\"]] + [pos for pos in frame_data[\"balls\"]]\n",
    "        writer.writerow(row)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    # Update previous frame\n",
    "    frame_num += 1\n",
    "    old_gray = frame_gray\n",
    "    old_results = results\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
